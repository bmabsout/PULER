%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     _______ _    _  _____       
%    |__   __| |  | |/ ____|
%       | |  | |__| | (___  
%       | |  |  __  |\___ \ 
%       | |  | |  | |____) |
%       |_|  |_|  |_|_____/
%
%     _               ____  
%    | |        /\   |  _ \ 
%    | |       /  \  | |_) |
%    | |      / /\ \ |  _ < 
%    | |____ / ____ \| |_) |
%    |______/_/    \_\____/ 
%
% _______ ______ __  __ _____  _            _______ ______ 
%|__   __|  ____|  \/  |  __ \| |        /\|__   __|  ____|
%   | |  | |__  | \  / | |__) | |       /  \  | |  | |__   
%   | |  |  __| | |\/| |  ___/| |      / /\ \ | |  |  __|  
%   | |  | |____| |  | | |    | |____ / ____ \| |  | |____ 
%   |_|  |______|_|  |_|_|    |______/_/    \_\_|  |______|
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% DONT CHANGE ANYTHING BEFORE THE "TITLE" SECTION.%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass{article} % Especially this!
% _____        _____ _  __          _____ ______  _____ 
%|  __ \ /\   / ____| |/ /    /\   / ____|  ____|/ ____|
%| |__) /  \ | |    | ' /    /  \ | |  __| |__  | (___  
%|  ___/ /\ \| |    |  <    / /\ \| | |_ |  __|  \___ \ 
%| |  / ____ \ |____| . \  / ____ \ |__| | |____ ____) |
%|_| /_/    \_\_____|_|\_\/_/    \_\_____|______|_____/ 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[margin=1.5in]{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage[numbers, square]{natbib}
% \usepackage{natbib}
\usepackage{fancybox}
\usepackage{epsfig}
\usepackage{soul}
\usepackage[shortlabels]{enumitem}
\usepackage[version=4]{mhchem}

\usepackage{multicol}
\usepackage{minted}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
}
\setlength{\marginparwidth}{3.4cm}

\bibliographystyle{abbrvnat} 

%#########################################################

%To use symbols for footnotes
\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
%To change footnotes back to numbers uncomment the following line
%\renewcommand*{\thefootnote}{\arabic{footnote}}

% Enable this command to adjust line spacing for inline math equations.
% \everymath{\displaystyle}

\newcommand{\PULER}{\mathsf{PULER}}
\newcommand{\key}[1]{\langle #1 \rangle}

\title{
\normalfont \normalsize 
\textsc{Boston University, 2019} \\
[10pt] 
\rule{\linewidth}{0.5pt} \\[6pt] 
\huge $\PULER$ \\
\rule{\linewidth}{2pt}  \\[10pt]
}
\author{Bassel El Mabsout}
\date{\normalsize April, 2023}

\begin{document}

\maketitle
\noindent

\tableofcontents

\newpage

\section{Introduction}
    Typical programming language compilers are comprised of various \textit{stages} that are chained together producing a final output from an initial input program.
    These stages can include parsing, renaming, type inference, optimization, and emission.
    For example, a C compiler takes as input a C program, which goes through these transformations and finally produces machine code.
    Similarly the Purescript \cite{purescript} compiler produces JavaScript. While these transformations share abstract language constructs like \textbf{let-in} statements, \textbf{lambda} abstractions, and \textbf{if-then-else} statements \cite{Pierce2002-px}, they also require transformation-specific information to be tracked.
    For instance, during type inference, a data-structure storing the language's expressions \textbf{decorated} with their types and ununified variables must be defined. \cite{JavaCompilerDesign}

    When compilers are implemented in a programming language supporting \textbf{Abstract Data Types (ADTs)} \cite{ADTs}, they often contain multiple ADTs for each transformation, leading to duplication of effort, functionality, and difficulty in keeping the language's \textit{constructs} in sync.
    Additionally, extending the language with new constructs becomes difficult as the language designer must add necessary mechanisms to every datatype and function.
    Without a core datatype, bugs may arise since some intermediary ADTs may be left untouched, and the compiler may not reject the updated code. This issue presents itself in multiple different compiler implementations \cite{GHC, ocaml}, and is the core focus of a body of existing work \cite{Torgersen2004, Axelsson, openfunctions}.

    Motivated by the ADT duplication problem, we explore another point in the \textit{design space} by introducing an experimental compiler with a differing architecture, and studying its implications in Section~\ref{compiler}.
    This compiler accepts $\PULER$ programs, a new experimental \textit{ML-based} programming language presented in Section~\ref{puler} of this document.
    It then invokes different transformation as required by the final output requested, for an example of the stages involved, see Section~\ref{compiler_stages}
    One of the distinctive features of $\PULER$ is defining \textbf{unification rules} for type mismatches, forming types themselves and being treated as \textit{first-class} citizens in the type system.
    In contrast, existing compilers mostly exit and produce an error upon a type mismatch.
    Existing works focusing on this issue of type error debugging \cite{min_type_error} generate orthogonal constraints which are separately represented and solved (e.g. via \textbf{SMT} solvers), producing errors which help users figure out the root cause. These ideas are discussed in Section~\ref{type-system}.
    
    % \subsection{Motivations}
    %     The main motivation of this project is to experiment on compiler architecture design with the goal of making it easy to experiment on programming language extendibility and on their feature sets. In doing so we investigated the following questions:
    % \begin{itemize}
    %     \item Whether structuring a compiler using recursion schemes and free monads (for composing effects) in Haskell would help with separation of concerns in the different compiler stages and whether that would allow for easily extending the language with new constructs.
    %     \item Whether sharing a main abstract datatype across transformations would force the handling of new constructs where needed.
    %     \item Whether the notion of mismatching types and ununified variables can be part of the type system, delaying when programs are rejected or accepted, conveying more information to users when debugging type errors.
    %     \item Whether the algorithm performing type checking can be separated from the constructs used to define the type system, relying only on the join semi-lattice structure of the datatype representing the type system.
    % \end{itemize}

\section{Compiler design}\label{compiler}
    On the implementation of compilers written in Haskell specifically, the work by \citet{najd2017trees} presents and implements "Trees that grow", a technique for "decorating" ADTs by using type families.
    They then rewrite the internals of the Glasgow Haskell Compiler (GHC) \cite{GHC} to make use of the method.
    In GHC, the data types for these transformations are large (dozens of types, hundreds of constructors) making them difficult to maintain.
    Their solution involves defining a single extensible ADT with Haskell's possible expressions.
    This allows different "decorations" of Haskell's Abstract Syntax Tree (AST) to be defined in separate parts of the compiler.
    Plugin writers then benefit from reusing the compiler as a library when extending the language.
    
    In the $\PULER$ compiler, each language construct is given a separate core parameterized type which is then reused across transformations.
    We then make use of deriving mechanisms to create reusable functionality across trees composed of these types.
    For example the following is the definition for the datatype of a Let expression:
    \begin{minted}{haskell}
    data Let expr = Let (Decs expr) expr
        deriving (Eq, Functor, Foldable, Traversable)
    \end{minted}
    This technique allows us to define dependencies between language constructs (here let expressions use declarations) without constraining the final tree structure and decorations added.
    The language designer can then work with each structure on its own, and then define an ADT combining them.
    This allows the separation of the logic handling each type of expression in the language from the logic handling their composition.
    As an example, we show how the parser for let expressions is defined:
    \begin{minted}{haskell}
    instance Parsable a => Parsable (Let a) where
      parser = Let
          <$> (begKeyword "let" *> parser)
          <*> (midKeyword "in" *> parser)
    \end{minted}
    Typeclasses allow us to define how each piece of the language can be parsed while remaining generic with respect to how subexpressions are composed.
    Contrasting this with the "Trees that grow" method, the structure of the language is solidified in a single ADT, and while they allow open extension to some parts of the language, they cannot introduce new language constructs.
    More information about the syntax of $\PULER$ is provided in Section~\ref{syntax}.
    
    \subsection{Recursion-Schemes}\label{recursion-schemes}
        In order to recursively connect subexpressions together, we form a core ADT:
    \begin{minted}{haskell}
    data Expr
      = Evar Var
      | Eapp (App Expr)
      | Elet (Let Expr)
      | Eif (If Expr)
      | Edecs (Decs Expr)
      | Elambda (Lambda (N.NonEmpty Var) Expr)
      | Efix (Fixer Expr)
      | Elit Lit
      | Eannotation (Annotated Expr NamedTypes)
        deriving (Eq, Generic)
    makeBaseFunctor ''Expr
    \end{minted}
        Recursion-schemes \cite{Meijer1991} allow recursive algorithms to decouple local computations from the patterns used in the recursive step.
        This allows us to treat our \textbf{Expr} datatype as an \textit{F-algebra}~\cite{falgebra} and write our transformations as combinations of algebras and co-algebras over similar types.
        Specifically, we make use of Haskell's recursion-schemes~\cite{kmett} library.
        Combined with the use of effect systems (Polysemy \cite{polysemy}), this allowed breaking down the transformations into many smaller subproblems, and then composing them together into the final computed value.
        The "makeBaseFunctor" template function creates an auxillary datatype, namely "ExprF" which now acts as our interface with recursion schemes.
        This general method of structuring the compiler, allowed us to define different ADTs specific to each transformation, yet shared information is retained via the different datatypes for each construct.
        For example, here's the definition of the ADT representing the possible values that the interpreter can produce:
    \begin{minted}{haskell}
      data Value = Vlit Lit
                 | Vlambda (Lambda (N.NonEmpty Var) LambdaBody)
                 | VDecs (Decs Value)
                 | Empty
    \end{minted}
        Notice how, even though we define a new ADT that must be changed when adding new language constructs, the actual datatypes are just wrappers connecting our general datatypes (such as Decs).
        This trades off some duplication for flexibility, as such this occupies a point in the design space between full duplication and "Trees that grow".
\subsection{Other compiler stages}\label{compiler-stages}
    This section contains the details of other compilation stages and of their implementation. They all make use of the aforementioned ideas for making compiler structuring decisions.
    \subsubsection{Renamer}\label{renamer}
    The renamer keeps track of the scope of each variable and renames overlapping variables to an incremented version so that we don't worry about scope in later compiler passes:
    \begin{minted}{haskell}
        -----INPUT-----
        x = 3;
        x = 4;
        z = "test";
        y = \x -> let f = 4 in f + x;
        main = x;
        -----RENAMED-----
        x = 3;
        x#1 = 4;
        z = "test";
        y = \x#2 -> let f = 4;
                    in ((Add f) x#2);
        main = x#1;
    \end{minted}
    
    This is the main renaming logic which just allows us to push and pop a variable stack:
    \begin{minted}{haskell}
        data Scope = Scope {numShadowing :: Shadowing, stack :: [Shadowing]}
        
        type Renamer = M.Map Var Scope
        
        insertToScope :: Var -> Renamer -> Renamer
        insertToScope =
          M.alter $ Just . \case
            Just (Scope g l) -> Scope (g + 1) (g + 1 : l)
            Nothing -> Scope 0 $ [0]
        
        removeFromScope :: Var -> Renamer -> Renamer
        removeFromScope = M.update \(Scope g l) -> Just (Scope g (tail l))
    \end{minted}
    A catamorphism is then used to recursively update the variables associated with individual scope levels, producing the final transformed AST.
    
    \subsubsection{Interpreter}\label{interpreter}
    This is $\PULER$'s interpreter, it works by first ``blinding" the original expression tree, meaning it hides the body of functions from recursion schemes so that we never evaluate the values inside of the bodies of functions. It then converts the AST into a Value type (as defined above).
    This is done with a catamorphism with access to a monad that keeps track of the scope of variables. The interpreter even correctly evaluates the program without a renaming step.
    \subsubsection{Autoformatter}
    This is the autoformatter that comes with $\PULER$, it appropriately indents new lines if there isn't too much width space. Here's a short program:
    \begin{minted}{haskell}
    x = \test -> if True then 1 else 2
    -----PARSED-----
    x = \test -> if True
                 then 1
                 else 2;
    \end{minted}
    Here's a longer one:
    \begin{minted}{haskell}
    -----INPUT-----
    x = \test -> if True then "this is a very long message" else let y = 3 in ""
    -----PARSED-----
    x = \test ->
        if True
        then "this is a very long message"
        else let y = 3;
             in "";
    \end{minted}
    Notice that it decided to insert a new line after $\to$ in the second case so that it can fit within 40 characters.
    Similar to how the parser is defined, each datatype has its own pretty printer, which is then stringed together forming the full pretty-printable expression type.
\subsubsection{Emission}\label{emission}
    Finally, we emit the typed language to Python. The output is auto-formatted so it retains some readability even after transformation. The runtime is fairly simple, consisting of a few functions allowing the direct translation of any $\PULER$ program into python. There are some extra tools in the emission code allowing the computation of the free variables computing the environment of every function and such, but for python since we can create lambdas, then there's no need to create closures ourselves. The compiler initially was targeting C, however the combination of partial applications and C having no ability to create lambdas meant, if done naively, the generated output would create n functions for every n variable function which was very unappealing. Another possibility is Mallocing the environment of a function upon creation. Storing it in a struct that also stores the arguments to the function, then when applying a single argument, simply assign the value to the argument in the struct. Now our function would be passed as a struct of arguments and an environment. When the last argument is provided, that's where we actually call the function. The only problem with this approach is that it requires tagging the functions to figure out when the final application is happening. The only ways of doing this that I've thought of end up coupling the language to the backend too much. So I opted to emit to a language with closures. Namely, python.
\subsection{REPL}\label{repl}
    The language also includes a Read Eval Print Loop, which allows users to run valid (or invalid) $\PULER$ and interact with the language. This works by using the conext associated to every stateful operation in our architecture. Meaning the same code that tracks information like the current scope of variables is reused in the repl to keep this state live. We can also get the benefit of providing features like autocomplete since the context is mostly tracked using dictionaries. Another feature is that we can load files into the repl, if you write a $\PULER$ program and save it, you can start a repl that evaluates it and allows you to write code with it as part of the context. I found this to be immensely useful when debugging.

\section{$\PULER$}\label{puler}
$\PULER$ is an experimental ML based programming language that is strictly evaluated, partially applied, implements a Hindley-Milner-based \cite{Hindley-Milner} type system (Section~\ref{type-system}), and is lexically scoped (Section~\ref{renamer}). It can be interpreted (Section~\ref{interpreter}) or compiled (Section~\ref{compiler}). There's also a Read Eval Print Loop (REPL) (Section~\ref{repl}) available so that one can interact with the language live. The core language is simple, containing a few data types and language constructs. It can be extended through either adding compiler stages or minimally changing the representation used by the compiler to introduce new features. The language is functional first, meaning functions are first class citizens, and it disallows mutation, making it a referentially-transparent language.
    
One interesting feature of $\PULER$ is that the type system represents type mismatches. Unification rules are defined for mismatching types. This contrasts with typical programming languages' type checking implementations, which exit and produce an error immediately upon mismatch. We motivate 

\subsection{Syntax}\label{syntax}
$\PULER$'s syntax is very similar to languages like SML and Haskell. The following is a high-level \textbf{BNF}\cite{BNF} with the details in Parser.hs:

\begin{align*}
     \key{abs} & ::= \backslash \key{var} \to \key{subexpr} \\
     \key{subexprs} & :: = \key{subexpr} | \key{subexpr} \; \key{subexprs}\\
     \key{app} & ::= (\key{subexpr} \; \key{subexprs})\\
     \key{lit} & ::= \key{string} \; | \; \key{integer} \; | \; \key{boolean} \; | \; \{\} \\
     \key{dec} & ::= \key{variable} \text{=} \key{subexpr} \\
     \key{decs} & ::= \key{dec} \; | \; \key{dec}\text{;} \; \key{decs} \\
     \key{let} & ::= \text{let}\; \key{declerations} \; \text{in} \; \key{subexpr} \\
     \key{fix} & ::= \text{fix} \; \key{var} \; \key{abs} \\
     \key{type} & ::= \key{type} \to \key{type} \; | \; \{\} \; | \; Int \; | \; Bool \; | \; Str \\
     \key{annotation} & ::= \key{subexpr} : \key{type} \\
     \key{subexpr} & ::= \key{abs} \; | \; \key{lit} \; | \; \key{let} \; | \; \key{fix} \; | \; \key{annotation} \; | \; \key{app}
\end{align*}

At the top level of a $\PULER$ file $\key{decs}$ are expected.

\subsection{Features}\label{features}
    \begin{itemize}
        \item Lexical scoping: The scope of every variable is exactly defined by the location of its definition. Meaning its scope is completely defined at compile time. Defining a variable with the same name as another variable that is in scope means that this new variable shadows the earlier defined one.
        \item Partially applied: Applying an argument to a 3 argument function returns a function of 2 arguments instead of being an error.
        \item Hindley-Milner-based type system: If the program is correct then no types will need to be written anywhere, it is all inferred.
        \item Strict evaluation: The language is strictly evaluated, meaning function arguments are evaluated before the function is.
        \item Immutable: Any operation or function cannot modify the value of an existing variable. This along with the ability to create pure functions makes the language referentially transparent (this behavior is not preserved when you use the only impure function in $\PULER$ which is \mintinline{haskell}{Print}). Meaning you can replace a variable by the statement used to create it. The $=$ operator is more like the mathematical definition of $=$ and less like the assignment we're used to in imperative programming languages.
    \end{itemize}

\subsection{Type system}\label{type-system}
Multiple previous works have focused on the problem of type error localization.
Some show relevant portions of failed type inference traces\cite{DUGGAN199637, type_errors_src}, others show a slice of the program involved in the error \cite{Gast2005, slicing_type_errors}.
Other methods repeatedly call the typechecker, finding several error sources \cite{constraint_errors}.
The most promising approach we've observed in this area comes from the works \citet{min_type_error, type_error_diagnose}, producing constraints which rank type errors and then are solved by an SMT solver.
$\PULER$ makes no such choices, instead of producing an error and exiting the computation, the $\PULER$ type system keeps track of type mismatches.
This is orthogonal to the works by \citet{min_type_error} as then the decision to show some errors can be taken later, or the user can be shown multiple different "views" of the possible errors that happened for flexibility in type error debugging.
Note that the $\PULER$ compiler cannot currently handle all kinds of type errors this way, as an infinite occurs check (for preventing infinite types) also results in the compiler exiting.


    Type inference in $\PULER$ converts an \mintinline{haskell}{Expr} to a \mintinline{haskell}{Cofree ExprF INamedTypes}, this just means that we're annotating each node of the recursive abstract syntax tree with a type. The type inference algorithm does the following: It initializes each expression with unification variables and relates the unification variables with inference rules. Then we ``propagate" \cite{propagators} the knowledge gained through a pass of applying the inference rules. We repeat this process (while doing occurs checks) until no further knowledge can be gained. When this is done we return the annotated tree. This is the datatype describing the types used for inference:
    \begin{minted}{haskell}
        data Itypes base
          = Iunif Name
          | IbaseType base
          | Iarrow (Itypes base) (Itypes base)
          | Imismatch [Itypes base]
    \end{minted}
    In order to precisely describe what it means for knowledge to increase, we allow any 2 types to be joined to create a type considered the least upperbound of both:
    \begin{minted}{haskell}
        instance Ord base => Semigroup (Itypes base) where
          -- this is actually a join semilattice
          a <> b | a == b = a
          Imismatch as <> Imismatch bs = Imismatch (nubQuick (as ++ bs))
          Iarrow a1 b1 <> Iarrow a2 b2 = Iarrow (a1 <> a2) (b1 <> b2)
          a@(Iunif _) <> (Iunif _) = a
          (Iunif a) <> b = b
          a <> (Iunif b) = a
          (Imismatch l) <> x = if x `elem` l then x else Imismatch (nubQuick $ x:l)
          x <> (Imismatch l) = if x `elem` l then x else Imismatch (nubQuick $ x:l)
          a <> b = Imismatch [a, b]
    \end{minted}
    When we have 2 different types we can now join them to create a \textit{``larger"} type. We now proceed by unifying types that are supposed to be equal (because of rules on the structure of the expression tree) by representing the types that are equal to each other as a disjoint set. Then we find the least upper bound of each disjoint set. Knowledge is then described as a map between each type and its corresponding ``joined" type. Once we have this map we can ``gain" knowledge by replacing any unification variables with a corresponding concrete type. This in turn will generate new types to unify. This process is repeated until this knowledge map is unchanging. What's nice about doing things this way is that we can give users as much information about the types of expressions as we can get even when the types mismatch or are kept ambiguous. Here's an example with mismatching and ununified types:
    \begin{minted}{haskell}
    x = 4;
    y = x + "string";
    main = (x 3);
    -----INFERRED-----
    x = 4:Int;
    y = ((Add x:[ Int
                , String
                , Int->?d ]):[ Int
                             , String ]->Int
           "string":String):[ Int
                            , String
                            , Int->?d ];
    main = (x:[Int, String, Int->?d]
              3:Int):?d;:{}
    \end{minted}
    Notice that there are 3 different type errors in here. First when we see the type [a, b] this means that the types a and b don't match. We can see here that the type of x is inferred to be \mintinline{haskell}{[Int, String, Int->?d]}. Second when we see a ? symbol this means it is a unification variable and that this variable remained ununifiable. Then notice that x it's self is actually used in three separate incompatible ways. First x is set to be the number 4 which is an Int, then we're adding a string to x but you can't add strings to numbers so that creates the first mismatch, the second mismatch comes from using x as a function in main. Given that we never use the result of the function this means we don't ``know" what the result type is, which is another type error. Even though the output is currently verbose we could simply query the type of specific variables and this ability allows tracking the trace of a mismatch which we also found useful.
    




\section{Examples}
\subsection{Example Program}
\begin{minted}{haskell}
    fib = fix fib \x ->
        if x == 0
        then 0
        else if x == 1
             then 1
             else (fib (x-1)) + (fib (x-2));
    
    main = (fib 8);
    >>
    21
\end{minted}

\subsection{Example Commands}
\subsubsection{REPL example}
Open a repl and run expressions as well as check their types:
\begin{minted}{bash}
    > PULER repl
    Welcome to PULER!
\end{minted}
\begin{minted}{haskell}
    λ> x = 1
    x = 1;
    λ> y = \z -> z
    y = \z -> <body>;
    λ> :t (y x)
    (y: Int -> Int x: Int): Int
    λ> (y x) + 1
    2
    λ> (Print "test")
    "test"
    {}
\end{minted}
\subsubsection{Compilation stages example}\label{compiler_stages}
Compile an example *.pul file implementing the factorial function
\mint{bash}|    > PULER example.pul|
\begin{minted}{haskell}
    -----INPUT-----
    fact = fix f \x ->
                  if x == 0
                  then 1
                  else let nextFac = x * (f (x - 1));
                           p = (Print (Int2Str nextFac))
                       in nextFac;
    main = let g = (fact 8) in {};
    
    -----PARSED-----
    fact = fix f \x -> if ((EqInt x) 0)
                       then 1
                       else let nextFac = ((Mul x) (f ((Sub x) 1)));
                                p = (Print (Int2Str nextFac));
                            in nextFac;
    main = let g = (fact 8);
           in {};
    -----RENAMED-----
    fact = fix f \x -> if ((EqInt x) 0)
                       then 1
                       else let nextFac = ((Mul x) (f ((Sub x) 1)));
                                p = (Print (Int2Str nextFac));
                            in nextFac;
    main = let g = (fact 8);
           in {};
    -----INFERRED-----
    fact = fix f \x -> if ((EqInt x:Int):Int->Bool 0:Int):Bool
                       then 1:Int
                       else let nextFac = ((Mul x:Int):Int->Int
                                             (f:Int->Int ((Sub x:Int):Int->Int
                                                            1:Int):Int):Int):Int;
                                p = (Print (Int2Str nextFac:Int):String):{};
                            in nextFac:Int:Int:Int:Int->Int;
    main = let g = (fact:Int->Int 8:Int):Int;
           in {}:{}:{};:{}
    -----CHECKED-----
    Typechecks!
    -----EVALUATED-----
    1
    2
    6
    24
    120
    720
    5040
    40320
    {}
    -----EMITTED-----
    fact = fix(lambda f: lambda x:(
        (
            1
        ) if (
            EqInt(x)(0)
        ) else (
            let(
              nextFac = Mul(x)(f(Sub(x)(1))),
            inn = lambda nextFac:(
              let(
                p = Print(Int2Str(nextFac)),
              inn = lambda p:(
                nextFac
              ))
            ))
        )
    ))
    main = let(
      g = fact(8),
    inn = lambda g:(
      unit
    ))
\end{minted}
\section{Installation}
Install the compiler by following these instructions:
\begin{enumerate}
    \item Clone the following repository: \href{https://github.com/bmabsout/PULER.git}{$\PULER$}
    \item Install the \href{https://nixos.org/nix/}{nix package manager}
    \item Navigate to the $\PULER$ folder
    \item Run the \mintinline{bash}{nix-shell} command which puts you in a reproducible environment with the exact packages (and packages versions) required to compile the compiler
    \item Compile the code by running \mintinline{bash}{ghc -O2 Main.hs}
    \item Now you can use the Compiler by calling \mintinline{bash}{./Main}
\end{enumerate}


\section {Conclusion}
    After multiple iterations of compiler design, $\PULER$ has converged to the idea of having main datatypes stringed together to form algebras on which the algorithms forming compiler stages are built upon. In exploring this architecture, we've built a full programming language with multiple interesting features. The architecture made it easy to use the compiler as a library and build a REPL for example with very minimal amounts of code. We did notice however, that even with careful design in avoiding duplication, there is still boilerplate code which duplicates parts of the core ADT throughout compiler transformations. The sum types used tag each alternative branch with a name which is unnecessary in our approach since the datatypes are already unique. As such, we believe connecting the types of expressions together via strongly typed heterogenous lists \cite{hlist} would lead to an even more terse and composable interface, we leave this as an exploration in future work. 
    At its current state, we found it easier to add any type of construct to the language and fill in the implementation gaps, than otherwise would be the case without this architecture.
    Another remaining challenge is targetting C as a backend, the limitations of which may strain the architectural decisions made in $\PULER$.

\bibliography{bibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document} 
